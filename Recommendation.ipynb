{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856193c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710,3321,1342,2033,3324,3895"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler  # MIN - MAX 정규화를 위한 라이브러리\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '../../assets/modules')\n",
    "import re\n",
    "from truckEDA import EDAHelper\n",
    "from datetime import datetime as dt\n",
    "from dotenv import dotenv_v\n",
    "alues\n",
    "import random\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "eda = EDAHelper()\n",
    "now = pd.to_datetime(dt.today())\n",
    "\n",
    "def call_mycar(df):\n",
    "    df = pd.merge(left=dfs['GROUP01']['trucks'], right=dfs['GROUP01']['dealer_cnt'], on='DAL_ID', how='left')\n",
    "    group2 = pd.merge(left=dfs['GROUP02']['trucks'], right=dfs['GROUP02']['dealer_cnt'], on='DAL_ID', how='left')\n",
    "    group3 = pd.merge(left=dfs['GROUP03']['trucks'], right=dfs['GROUP03']['dealer_cnt'], on='DAL_ID', how='left')\n",
    "    return df\n",
    "\n",
    "def preprocess_mycar(df):\n",
    "    df = eda.rename_column(df, [\"TB_MYCAR\", \"TB_DEALER\", \"TB_CLICK\"]).rename(columns={\n",
    "        'DAL_TOTAL_UPT_CNT': '딜러 등록대수',\n",
    "        '종사원증 번호': '종사원증 번호여부',\n",
    "        '상세설명': '상세설명 길이'\n",
    "    })\n",
    "    \n",
    "    df['가입일자'] = df['가입일자'].str.replace(pat=r'[a-zA-Z]+', repl= r' ', regex=True)\n",
    "    df['마지막 로그인 시간'] = df['마지막 로그인 시간'].str.replace(pat=r'[a-zA-Z]+', repl= r' ', regex=True)\n",
    "    df['등록일자'] = df['등록일자'].str.replace(pat=r'[a-zA-Z]+', repl= r' ', regex=True)\n",
    "\n",
    "#     df['소분류'] = eda.rename_value(df['소분류'])\n",
    "\n",
    "#     df['브랜드'] = eda.rename_value(df['브랜드'])\n",
    "    \n",
    "    df[\"상세설명 길이\"] = df[\"상세설명 길이\"].str.replace(pat=r'[^\\w]', repl=r'', regex=True)\n",
    "    df[\"상세설명 길이\"] = df[\"상세설명 길이\"].str.len().fillna(0)\n",
    "    \n",
    "    df['마지막 로그인 시간'] = pd.to_datetime(df['마지막 로그인 시간'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    df['가입일자'] = pd.to_datetime(df['가입일자'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    df['등록일자'] = pd.to_datetime(df['등록일자'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    \n",
    "    df[\"종사원증 번호여부\"] = df[\"종사원증 번호여부\"].str.len()\n",
    "    \n",
    "    df.loc[df[\"종사원증 번호여부\"] <= 5, '종사원증 번호여부'] = 0\n",
    "    df.loc[df[\"종사원증 번호여부\"] > 5, '종사원증 번호여부'] = 1\n",
    "    \n",
    "    # MCR_IMG1 ~ MCR_IMG20 이미지 파일은 존재할경우 1, Null일경우 0으로 변환\n",
    "    for i in range(1, 21):\n",
    "        df[['이미지{}'.format(i)]] = df[['이미지{}'.format(i)]].where(df[['이미지{}'.format(i)]].isnull(), 1).fillna(0)\n",
    "\n",
    "    # 변환한 값에 대해 모두 더한값을 저장하는 MCR_IMG 컬럼 생성\n",
    "    df['이미지 수'] = 0\n",
    "\n",
    "    # 연산(Count MCR_IMG1 ~ MCR_IMG20) & drop 이미지 columns\n",
    "    for i in range(1, 21):\n",
    "        df['이미지 수'] += df[f'이미지{i}']\n",
    "        df.drop(columns=[f\"이미지{i}\"], inplace=True)\n",
    "        \n",
    "    df['연식'] = pd.to_datetime(df['연식'], format='%Y-%m-%d', errors='coerce')\n",
    "    df.drop(df[df['연식'] > now].index, inplace=True)\n",
    "    \n",
    "    df['번호판 종류'] = df['번호판 종류'].replace('0402', 1).replace('0401', 0)\n",
    "    \n",
    "    df['실매물 확인여부'] = df['실매물 확인여부'].replace('N', 0).replace('Y', 1)\n",
    "    df['직거래 매물여부'] = df['직거래 매물여부'].replace('N', 0).replace('Y', 1)\n",
    "    \n",
    "    df['헛걸음보상제공여부'] = df['헛걸음보상제공여부'].replace('N', 0).replace('Y', 1)\n",
    "    \n",
    "    df['마지막 로그인 시간'].fillna(df['가입일자'], inplace=True)\n",
    "    \n",
    "    df['톤수'] = df['톤수'].replace('기타', '0').astype(float)\n",
    "    df['톤수'] = eda.ton_masking(df, '톤수')\n",
    "    df['주행거리'] = df['주행거리'].astype(\"int64\")\n",
    "    df['가격'] = df['가격'].astype(\"int64\")\n",
    "\n",
    "    df['일평균등록매물'] = (df['마지막 로그인 시간'] - df['가입일자']).dt.days / df['딜러 등록대수']\n",
    "    df['일평균조회수'] = (df['클릭횟수'] / ((now - df['등록일자']).dt.days + 1)).fillna(0)\n",
    "    df['일평균조회수'] = -df['일평균조회수']\n",
    "    \n",
    "    df = df.drop(columns=[ '등록일자', '가입일자', '마지막 로그인 시간', '클릭횟수', '딜러 아이디', '딜러 등록대수'])\n",
    "    # 일평균 주행거리가 600km 초과인 매물 drop\n",
    "    df = df.drop(df[df['주행거리'] / ((now - df['연식']).dt.days) > 600].index)\n",
    "    # 차량상태 점수를 위한 주행거리 뒤집기\n",
    "    df['주행거리'] = -df['주행거리']\n",
    "\n",
    "    # 100만원 이하, 3억 이상인 차량 drop\n",
    "    min_drop = 100\n",
    "    df = df.drop(df[df['가격'] <= min_drop].index)\n",
    "    max_drop = 30000\n",
    "    df = df.drop(df[df['가격'] >= max_drop].index)\n",
    "    \n",
    "    df.set_index('내차사기 아이디', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_car_bias_points(df, user_points):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    car_ton = [\n",
    "            (1, 1.2),\n",
    "            (1.3, 4.5),\n",
    "            (4.5, 5),\n",
    "            (5, 11.5),\n",
    "            (11.5, 27),\n",
    "        ]\n",
    "    \n",
    "    car_brand = [\n",
    "        ('C'),\n",
    "        ('D')\n",
    "    ]\n",
    "    \n",
    "    # 신뢰도 높음 점수\n",
    "    df_reliability = df[[\n",
    "        \"실매물 확인여부\",\n",
    "        \"종사원증 번호여부\",\n",
    "        \"일평균등록매물\",\n",
    "        \"헛걸음보상제공여부\",\n",
    "       ]]\n",
    "    reliability = scaler.fit_transform(df_reliability)\n",
    "\n",
    "    # 차량상태 좋음 점수\n",
    "    df_condition = df[[\n",
    "        \"주행거리\",\n",
    "        \"가격\",\n",
    "        \"상세설명 길이\",\n",
    "        \"이미지 수\",\n",
    "       ]]\n",
    "\n",
    "    condition = scaler.fit_transform(df_condition)\n",
    "    condition = np.concatenate((condition, scaler.fit_transform(df[[\"연식\"]])), axis=1)\n",
    "    # 보유자산 낮음 점수\n",
    "    df_asset = df[[\n",
    "        \"직거래 매물여부\",\n",
    "        \"번호판 종류\",\n",
    "        \"일평균조회수\",\n",
    "    ]]\n",
    "\n",
    "    asset = scaler.fit_transform(df_asset)\n",
    "    \n",
    "     # 톤 점수\n",
    "    dfa = df.copy()\n",
    "    dfa['톤수_점수'] = None\n",
    "    for i, t in enumerate(car_ton):\n",
    "        dfa.loc[\n",
    "            (dfa['톤수'] >= t[0]) & (dfa['톤수'] <= t[1]), '톤수_점수'\n",
    "        ] = (len(car_ton) / (len(car_ton) * (len(car_ton) - 1))) * ((i + 1) - 1)\n",
    "    ton = scaler.fit_transform(pd.DataFrame(-abs(dfa['톤수_점수'] - user_points['TON']['Q1'])))\n",
    "\n",
    "    # 브랜드 점수\n",
    "    dfa_2 = df.copy()\n",
    "    dfa_2['브랜드_점수'] = None\n",
    "    for i, b in enumerate(car_brand):\n",
    "        globals()[\"i_temp\"] = i\n",
    "        k = dfa_2.loc[\n",
    "            (dfa_2['브랜드'].str.contains(b)), '브랜드_점수'\n",
    "        ] = (len(car_brand) / (len(car_brand) * (len(car_brand) - 1))) * ((i + 1) - 1) \n",
    "        l = dfa_2['브랜드_점수']\n",
    "    brand = scaler.fit_transform(pd.DataFrame(-abs(dfa_2['브랜드_점수'] - user_points['BRAND']['Q1'])))\n",
    "    \n",
    "    df_knn = pd.DataFrame({\n",
    "        'RELIABILITY': (reliability.sum(axis=1) / reliability.shape[1]),\n",
    "        'CONDITION': (condition.sum(axis=1) / condition.shape[1]),\n",
    "        'ASSET': (asset.sum(axis=1) / asset.shape[1]),\n",
    "        'TON': (ton.sum(axis=1) / ton.shape[1]),\n",
    "        'BRAND' : (brand.sum(axis=1) / brand.shape[1]),\n",
    "    }, index=df.index,)\n",
    "    globals()[\"df_knn_temp_2\"] = df_knn\n",
    "    return df_knn\n",
    "\n",
    "def get_user_bias_points(questions, user_points):\n",
    "    user_bias_points = dict()\n",
    "    for (axis_question, quests_question), (axis_answer, quests_answer) in zip(questions.items(), user_points.items()):\n",
    "        user_bias_points[axis_answer] = list()\n",
    "        for (q_num, quest_question), (a_num, quest_answer) in zip(quests_question.items(), quests_answer.items()):\n",
    "            user_bias_points[axis_answer].append((quest_question[\"QUESTION_NUMBER\"] / (quest_question[\"QUESTION_NUMBER\"] * (quest_question[\"QUESTION_NUMBER\"] - 1))) * (quest_answer - 1))\n",
    "        user_bias_points[axis_answer] = sum(user_bias_points[axis_answer]) / len(user_bias_points[axis_answer])\n",
    "  \n",
    "    return user_bias_points\n",
    "\n",
    "def sort_by_distance(user_bias_points, df_knn):\n",
    "    X, Y, Z, T, B = np.array(df_knn['RELIABILITY']), np.array(df_knn['CONDITION']), np.array(df_knn['ASSET']), np.array(df_knn['TON']), np.array(df_knn['BRAND'])\n",
    "    \n",
    "    distance = np.sqrt(\n",
    "                ((X - user_bias_points['RELIABILITY']) ** 2) +\n",
    "                ((Y - user_bias_points['CONDITION']) ** 2) +\n",
    "                ((Z - user_bias_points['ASSET']) ** 2) +\n",
    "                ((T - user_bias_points['TON']) ** 2) +\n",
    "                ((B - user_bias_points['BRAND']) ** 2)\n",
    "            )\n",
    "    globals()[\"distance\"] = distance\n",
    "    df_knn['거리'] = distance\n",
    "    \n",
    "    result_ID = df_knn.sort_values(by='거리').index[:6]\n",
    "    globals()[\"result_ID\"] = result_ID\n",
    "    return result_ID\n",
    "\n",
    "def print_recommendation(recommendation_id):\n",
    "    MEM_REC_CAR = re.sub(' ', '', str(list(recommendation_id))[1:-1])\n",
    "\n",
    "    if not MEM_REC_CAR:\n",
    "        print('0', end='')\n",
    "    if MEM_REC_CAR:\n",
    "        print(f'{MEM_REC_CAR}', end='')\n",
    "\n",
    "\n",
    "def KNN(df, questions, user_points):\n",
    "    # get raw data\n",
    "#     df_mcr = call_mycar(df)\n",
    "\n",
    "    # 전처리\n",
    "    df_mcr_cleansed = df.copy()\n",
    "    df_mcr_cleansed = preprocess_mycar(df_mcr_cleansed)\n",
    "    globals()[\"df_mcr_cleansed\"] = df_mcr_cleansed\n",
    "\n",
    "    # 매물 feature points\n",
    "    try:\n",
    "        user_bias_points = get_user_bias_points(questions, user_points)\n",
    "        globals()[\"user_bias_points_temp\"] = user_bias_points\n",
    "        df_knn = get_car_bias_points(df_mcr_cleansed, user_points)\n",
    "        globals()[\"df_knn_temp\"] = pd.merge(df_mcr_cleansed.copy().reset_index(), df_knn.copy().reset_index(), how='left', on='내차사기 아이디')\n",
    "        recommend_truck = sort_by_distance(user_bias_points, df_knn)\n",
    "        globals()[\"recommend_truck_temp\"] = recommend_truck\n",
    "    except ValueError:\n",
    "        recommend_truck = ''\n",
    "# get_car_bias_points(get_survey_brand(preprocess_mycar(call_mycar(df).copy()), BRAND_NUM)))        \n",
    "    print_recommendation(recommend_truck)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # 메타 질문 데이터는 꼭 json화 돼 있어야 됨\n",
    "    questions = {\n",
    "        \"RELIABILITY\": {\n",
    "            f\"Q{i+1}\": {\"QUESTION\": \"질문 예시\", \"QUESTION_NUMBER\": random.randint(2, 5)} for i in range(random.randint(3, 7))\n",
    "        },\n",
    "        \"CONDITION\": {\n",
    "            f\"Q{i+1}\": {\"QUESTION\": \"질문 예시\", \"QUESTION_NUMBER\": random.randint(2, 5)} for i in range(random.randint(3, 7))\n",
    "        },\n",
    "        \"ASSET\": {\n",
    "            f\"Q{i+1}\": {\"QUESTION\": \"질문 예시\", \"QUESTION_NUMBER\": random.randint(2, 5)} for i in range(random.randint(3, 7))\n",
    "        },\n",
    "        \"TON\": {\n",
    "            \"Q1\":{\n",
    "                \"QUESTION\": \"질문 예시\",\n",
    "                \"QUESTION_NUMBER\": 5,\n",
    "            }\n",
    "        },\n",
    "        \"BRAND\": {\n",
    "            \"Q1\":{\n",
    "                \"QUESTION\": \"질문 예시\",\n",
    "                \"QUESTION_NUMBER\": 2,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    user_points = dict() # 이거는 파라미터로 받아야 됨\n",
    "    for axis, quests in questions.items():\n",
    "        user_points[axis] = dict()\n",
    "        for q_num, quest in quests.items():\n",
    "            user_points[axis][q_num] = random.randint(1, quest[\"QUESTION_NUMBER\"])\n",
    "    df = pd.merge(left=df_truck, right=df_dealer_cnt, on='DAL_ID', how='left')\n",
    "    KNN(df, questions, user_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4204eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
